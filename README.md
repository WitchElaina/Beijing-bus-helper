# Beijing-bus-helper
USTB人工智能大作业, 北京公交换乘助手
## Development
### 数据获取
使用爬虫获取数据, 目标网站为https://bus.mapbar.com/

首先从该网站的导航页爬取每条公交线路的URL, 随后从获得的URL中获取每条线路的信息

在处理DOM结构时需要用到beautifulsoup4, 首先进行安装
```shell
pip3 install beautifulsoup4 lxml
```

`url_robot.py`负责将导航页的地址进行统一抓取, 完成使用`per_robot.py`逐URL抓取站点信息, 最终结果保存在`st.txt`中, 格式如下:

```text
线路名称->['站点', '站点', ...]
11路->['大北窑东', '八王坟南', '北京东站北', '九龙山', '珠江帝景', '大郊亭桥西', '大郊亭桥东', '东石门', '唐家村', '小海子', '四根旗杆', '方家村', '朝阳半壁店', '观音堂北', '观音堂', '古塔公园', '王四营', '王四营桥东', '孛罗营村北', '孛罗营']
```

### 数据处理
站点存储采用txt方式进行纯文本存储, 读取时调用`prase.py`中的方法
